---
title: "Time zero normalization with the Multivariate Gaussian distribution"
author: "Sean Hackett"
date: "9/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

Timecourses are one of the most powerful experimental designs in biology 

because both the rapid and gradual responses 

I'll use genes as short-hand for whatever features that we might be working with since I've primarily worked with these methods in the context of gene expression data.

Most timecourse experiments 


## Our timecourse experiment

```{r env_setup}
library(dplyr)
library(ggplot2)
library(tidyr)

library(future)
plan("multicore")

# global options
theme_set(theme_bw())
```

```{r simulate_timecourses}
timepts <- c(0, 5, 10, 20, 30, 40, 60, 90) # time points measured
measurement_sd <- 0.5 # standard deviation of Gaussian noise added to each observation
total_measurements <- 1000 # total number of genes
signal_frac <- 0.2 # what fraction of genes contain real signal

set.seed(1234)

# simulate timecourses containing signal 

alt_timecourses <- impulse::simulate_timecourses(n = total_measurements * signal_frac,
                                                 timepts = timepts,
                                                 prior_pars = c(v_sd = 0.8,
                                                                rate_shape = 2,
                                                                rate_scale = 0.25,
                                                                time_shape = 1,
                                                                time_scale = 30),
                                                 measurement_sd = measurement_sd) %>%
  unnest_legacy(measurements) %>%
  select(-true_model) %>%
  mutate(signal = "contains signal") %>%
  # drop timecourses where no true value's magnitude is greater than 1 (these
  # aren't really signal containing
  group_by(tc_id) %>%
  filter(any(abs(sim_fit) > 1)) %>%
  ungroup()

knitr::kable(alt_timecourses %>% slice(1:length(timepts)))
```

```{r null_timecourses}
null_timecourses <- crossing(tc_id = seq(max(alt_timecourses$tc_id) + 1, total_measurements),
                time = timepts) %>%
  mutate(signal = "no signal",
         sim_fit = 0,
         abundance = rnorm(n(), 0, measurement_sd))

simulated_timecourses <- bind_rows(alt_timecourses, null_timecourses) %>%
  mutate(signal = factor(signal, levels = c("no signal", "contains signal")))
```


```{r timecourse_examples}
example_tcs <- simulated_timecourses %>%
  distinct(signal, tc_id) %>%
  group_by(signal) %>%
  sample_n(5) %>%
  mutate(label = as.character(1:n()))

simulated_timecourses %>%
  inner_join(example_tcs, by = c("signal", "tc_id")) %>%
  ggplot(aes(x = time, color = label)) +
  geom_path(aes(y = sim_fit)) +
  geom_point(aes(y = abundance)) +
  facet_wrap(~ signal, ncol = 1, scale = "free_y") +
  scale_y_continuous("Abundance") +
  scale_color_brewer("Example Timecourse", palette = "Set2") +
  ggtitle("Simulated timecourses with and without signal", "line: true values, points: observed values") +
  theme(legend.position = "bottom")
```

## Models to try

```{r}
nested_timecourses <- simulated_timecourses %>%
  nest(timecourse_data = -c(signal, tc_id)) 

nested_timecourses
```

### Linear, quadratic, cubic regression

```{r}
library(broom)
library(furrr)
library(gam)

fit_regression <- function (one_tc, model_type = "polynomial", degree = 1) {

  if (model_type == "polynomial") {
    polynomial_model <- lm(abundance ~ poly(time, degree = degree, raw = TRUE), data = one_tc)
    null_model <- lm(abundance ~ 1, data = one_tc)
    model_anova <- anova(null_model, polynomial_model)
  } else if (model_type == "gam") {
    model_anova <- gam(abundance ~ s(time), data = one_tc)
  } else {
    stop ("not a valid model_type")
  }
  
  model_anova %>%
    broom::tidy() %>%
    filter(!is.na(statistic))
}

standard_models <- nested_timecourses %>%
  mutate(linear_fit = future_map(timecourse_data, fit_regression, model_type = "polynomial"),
         cubic_fit = future_map(timecourse_data, fit_regression, model_type = "polynomial", degree = 3),
         gam_fit = future_map(timecourse_data, fit_regression, model_type = "gam"))
```

```{r}
fdr_control <- function(pvalues) {
  qvalue::qvalue(pvalues)$qvalues 
}

all_model_fits <- standard_models %>%
  select(-timecourse_data) %>%
  gather(model_type, model_data, -tc_id, -signal) %>%
  unnest(model_data) %>%
  group_by(model_type) %>%
  mutate(qvalue = fdr_control(p.value),
         discovery = ifelse(qvalue < 0.1, "positive", "negative"))

ggplot(all_model_fits, aes(x = p.value, fill = discovery)) +
  facet_grid(signal ~ model_type) +
  geom_histogram(bins = 25) +
  scale_fill_brewer(palette = "Set1")
```

```{r}
tricky_tcs <- all_model_fits %>%
  filter(model_type == "gam_fit", signal == "contains signal") %>%
  arrange(desc(qvalue)) %>%
  slice(1:8)

simulated_timecourses %>%
  semi_join(tricky_tcs, by = "tc_id") %>%
  ggplot(aes(x = time, color = as.character(tc_id))) +
  geom_path(aes(y = sim_fit)) +
  geom_point(aes(y = abundance)) +
  facet_wrap(~ signal, ncol = 1, scale = "free_y") +
  scale_y_continuous("Abundance") +
  scale_color_brewer("Example Timecourse", palette = "Set2") +
  ggtitle("Timecourses missed by GAM", "line: true values, points: observed values") +
  theme(legend.position = "bottom")
```






## Timecourse level significance

If we want to test whether full timecourses are explainable by timecourse level noise then it is useful to simulate data which mimimics such timecourses. In such timecourses, observations are drawn from independent log-normals and the log fold changes of later timepoints are found relative to time zero (i.e. $log_2f_{t} = \log_2x_t - \log_2x_1)$)



```{r fig.height = 10, fig.width = 10}
n <- 20000
timepts <- 8
timecourses <- expand.grid(feature = 1:n, time = 1:timepts, stringsAsFactors = FALSE) %>%
  dplyr::mutate(value = rnorm(n())) %>%
  dplyr::group_by(feature) %>%
  dplyr::mutate(tzero_value = value[time == 1]) %>%
  dplyr::mutate(tzero_diff = value - tzero_value) %>%
  dplyr::filter(time != 1)
timecourse_split <- timecourses %>%
  dplyr::filter(time %in% c(2:timepts)) %>%
  dplyr::select(feature, time, tzero_value, tzero_diff) %>%
  tidyr::spread(time, tzero_diff)
knitr::kable(head(timecourse_split,10))

ggplot(timecourse_split, aes(x = `2`, y = `3`, color = tzero_value)) + geom_point() +
  scale_color_gradient2('Time zero value', low = "GREEN", high = "RED", mid = "BLACK", midpoint = 0, breaks = -4:4, limits = c(-4,4)) +
  coord_cartesian(xlim = c(-5,5), ylim = c(-5,5)) +
  theme_minimal()
```

Based on the value of time zero, which all subsequent time points are normalized with respect to, these later timepoints are biased such that they are all higher or lower than otherwise expected. Because of the time zero normalization, in order to test for timecourse-level signal based on the aggregate signal of all observations, we need to account for the dependence of these observations. Luckily, the form of this dependence is quite straight-forward.

```{r}
cov(timecourse_split[,3:(timepts+1)])
```

Observations variances are $2\text{Var}(\log_2x_t)$ because $\mathcal{N}(\mu_{A}, \sigma^{2}_{A}) - \mathcal{N}(\mu_{B}, \sigma^{2}_{B}) = \mathcal{N}(\mu_{A} - \mu_{B}, \sigma^{2}_{A} + \sigma^{2}_{B})$. Observation covariances are $\text{Var}(\log_2x_t)$ because of the shared normalization to time zero.

Normalization of Normal (or log-Normal) observations to a common reference produces a Multivariate Normal distribution.

$$
z_{it} = \frac{f_{it}}{\sigma_{i}^{(f)}}
$$

$$
\mathbf{z}_{iT} \sim \mathcal{MN}\left(\mu = \mathbf{0}, \Sigma = 
\begin{bmatrix}
    1 & 0.5 & \dots  & 0.5 \\
    0.5 & 1 & \dots  & 0.5 \\
    \vdots & \vdots & \ddots & \vdots \\
    0.5 & 0.5 & \dots  & 1
\end{bmatrix}\right)
$$

```{r}
timecourse_covariance <- matrix(1, nrow = timepts-1, ncol = timepts-1)
diag(timecourse_covariance) <- 2
# simultate draws from multivariate normal
library(mvtnorm)
r_multivariate_normal <- rmvt(10000, sigma = timecourse_covariance, df = 0)
r_multivariate_pvalues <- sapply(1:nrow(r_multivariate_normal), function(i){
  pmvt(lower=rep(-Inf,ncol(r_multivariate_normal)), upper=r_multivariate_normal[i,], sigma = timecourse_covariance, df = 0)
})
r_multivariate_mahalanobis_dist <- mahalanobis(r_multivariate_normal, center = rep(0, times = ncol(timecourse_covariance)), cov = timecourse_covariance, inverted = FALSE)
# test multivariate normality
hist(pchisq(r_multivariate_mahalanobis_dist, df = ncol(timecourse_covariance)), breaks = 50)
# test timecourse samples for multivariate normality
time_course_mahalanobis_dist <- mahalanobis(timecourse_split[,-c(1:2)], center = rep(0, ncol(timecourse_covariance)), cov = timecourse_covariance)
hist(pchisq(time_course_mahalanobis_dist, df = ncol(timecourse_covariance)), breaks = 50)
```

## This test is rather affected by single observation outliers -- we can try calculating distance when holding out different time points

What to do if time zero is the bad array?

```{r eval = FALSE}
timecourses_bad_array <- timecourses %>%
  # add strong batch effect in one time point
  dplyr::mutate(tzero_diff = ifelse(time == 2, tzero_diff + rnorm(n(), 0, 3), tzero_diff)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(time %in% c(2:timepts)) %>%
  dplyr::select(feature, time, tzero_value, tzero_diff)
time_course_mahalanobis_dist_bad_array <- mahalanobis((timecourses_bad_array %>%
  tidyr::spread(time, tzero_diff))[,-c(1:2)], center = rep(0, ncol(timecourse_covariance)), cov = timecourse_covariance)
hist(pchisq(time_course_mahalanobis_dist_bad_array, df = ncol(timecourse_covariance), lower.tail = FALSE), breaks = 50)
held_out_times <- expand.grid(held_out_t = 2:timepts, nonzero_time = 2:timepts, stringsAsFactors = FALSE) %>%
    dplyr::filter(nonzero_time != held_out_t) %>%
    dplyr::left_join(timecourses_bad_array, by = c("nonzero_time" = "time")) %>%
    dplyr::group_by(held_out_t, feature) %>%
    dplyr::mutate(nonzero_time_order = 1:n()) %>%
    dplyr::select(-nonzero_time) %>%
    tidyr::spread(nonzero_time_order, tzero_diff)
held_out_times <- held_out_times %>%
  dplyr::ungroup() %>%
  dplyr::mutate(mahalanobis_d = mahalanobis(held_out_times[4:9], center = rep(0, timepts-2), cov = timecourse_covariance[1:(timepts-2), 1:(timepts-2)])) %>%
  dplyr::group_by(feature) %>%
  dplyr::arrange(feature, mahalanobis_d) %>%
  dplyr::slice(1) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(mahalanobis_p = pchisq(mahalanobis_d, df = timepts-2, lower.tail = FALSE))
hist(held_out_times$mahalanobis_p, breaks = 50)
```

## Load dataset and timecourse-level noise estimates (any estimate of a timecourse's noise can be plugged in)

```{r}
library(dynamicyeast)
suppressPackageStartupMessages(library(dplyr))
library(qvalue)
library(ggplot2)
source("../code/R/2_component_noise.R")
cleaned_dataset <- dynamicyeast::format_expression_data("~/Google Drive/transcription_dynamics/per_time_clean_interp.tsv", is_log_ratio = TRUE)
noise_model <- estimate_gene_fc_noise(cleaned_dataset,
                                     step_fraction = 0.1,
                                     quantile_range_val = 0.95,
                                     n_timepts = 4,
                                     iter_num = 200)
```

```{r}
standardized_fold_changes <- cleaned_dataset %>%
  dplyr::filter(log2_ratio != 0) %>%
  dplyr::left_join(noise_model$gene_noise, by = "gene") %>%
  dplyr::left_join(noise_model$timecourse_noise, by = c("TF", "strain", "date", "restriction", "mechanism")) %>%
  # calculate a z-score for each observation using its gene-level standard deviation
  dplyr::mutate(z_score_fc = log2_ratio / sqrt(gene_var + tc_var)) %>%
  # split timecourses up based on number of timepoints since all timecourse z-scores with the same n will follow the same null distribution
  dplyr::group_by(TF, strain, date, restriction, mechanism, gene) %>%
  dplyr::mutate(nonzero_time_order = 1:n(),
                n_times = n()) %>%
  dplyr::ungroup() %>%
  dplyr::select(-time, -ratio, -log2_ratio, -gene_var, -tc_var) %>%
  plyr::dlply(.variables = "n_times", dplyr::tbl_df)
multivariate_normal_tc_signif <- parallel::mclapply(standardized_fold_changes, function(a_times_set) {
  
  n_times <- a_times_set$n_times[1]
  
  timecourse_spread <- a_times_set %>%
    dplyr::select(-n_times) %>%
    tidyr::spread(nonzero_time_order, z_score_fc)
  
  # pull out time component and test calculate mahalanobis distance
  
  timecourse_matrix <- timecourse_spread %>%
    dplyr::select(-c(TF, strain, date, restriction, mechanism, gene)) %>%
    as.matrix()
  
  tc_sigma <- matrix(0.5, nrow = n_times, ncol = n_times)
  diag(tc_sigma) <- 1
  
  #full_tc_mahalanobis_d <- mahalanobis(timecourse_matrix, center = rep(0, times = n_times), cov = tc_sigma)
  
  # hold out each datapoint seperately and take the minimum distance (check for examples where distance is driven by 1 point)
  
  # generate all timecourses of n-1 size
  #expand.grid(held_out_t = 1:n_times, nonzero_time_order = 1:n_times, stringsAsFactors = FALSE) %>%
  #  dplyr::filter(nonzero_time_order != held_out_t) %>%
  #  dplyr::left_join(a_times_set, by = "nonzero_time_order") %>%
  #  dplyr::group_by(TF, strain, date, restriction, mechanism, gene) %>%
  #  dplyr::mutate(nonzero_time_order = 1:n()) %>%
  #  tidyr::spread(nonzero_time_order, z_score_fc)
  
  timecourse_spread %>%
    dplyr::select(TF, strain, date, restriction, mechanism, gene) %>%
    dplyr::mutate(mahalanobis_d = mahalanobis(timecourse_matrix, center = rep(0, times = n_times), cov = tc_sigma),
                  p_multivariate_normal = pchisq(mahalanobis_d, df = n_times, lower.tail = FALSE))
}, mc.cores = 4) %>%
  dplyr::bind_rows()
  
hist(multivariate_normal_tc_signif$p_multivariate_normal, breaks = 100)
